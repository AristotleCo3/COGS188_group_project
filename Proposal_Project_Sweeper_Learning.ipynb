{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 188 - Project Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You have the choice of doing either (1) an AI solve a problem style project or (2) run a Special Topics class on a topic of your choice.  If you want to do (2) you should fill out the _other_ proposal for that. This is the proposal description for (1).\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like 8-Queens or a small Traveling Salesman Problem or similar\n",
    "- If its the kind of problem (e.g., RL) that interacts with a simulator or live task, then the problem will have a reasonably complex action space. For instance, a wupus world kind of thing with a 9x9 grid is definitely too small.  A simulated mountain car with a less complex 2-d road and simplified dynamics seems like a fairly low achievement level.  A more complex 3-d mountain car simulation with large extent and realistic dynamics, sure sounds great!\n",
    "- If its the kind of problem that uses a dataset, then the dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training an unsupervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "- The project must include some elements we talked about in the course\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your AI system. Generally RL tasks may require a huge amount of training, so extensive grid search is unlikely to be possible. However expoloring a few reasonable hyper-parameters may still be possible. \n",
    "- You will evaluate the performance of your AI system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "\n",
    "- Keyi Yu\n",
    "- Fatima Dong\n",
    "- Kayla Huynh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This project aims to build an AI model that solves the game Minesweeper using reinforcement learning algorithms. Minesweeper is a logic based game where the goal is to uncover all non-mine cells while avoiding mines. The game environment is a grid where each cell can either contain a mine or be safe. The numbers on the revealed cells tell you the number of adjacent mines. If you accidentally uncover the mine cell, then the game will end. The dataset is generated from a Python-based Minesweeper implementation, consisting of game states, player actions, and board configurations.\n",
    "\n",
    "The mindsweeper solver will operate as a rational agent by optimizing its performance uncovering safe cells, in the stochastic environment. We will be using search algorithms and heuristic strategies to effectively solve the problem. To evaluate performance, we will use win rate and average game duration as key metrics.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Minesweeper is a single-player game where players must uncover all safe tiles without clicking on a mine! Safe squares provide numerical clues indicating how many mines are within a one-tile radius. The game features three official board sizes: Beginner (8×8 grid with 10 mines), Intermediate (16×16 grid with 40 mines), and Expert (16×30 grid with 90 mines). Clicking on a mine ends the game immediately, while selecting a safe tile may reveal numbers or automatically clear nearby squares. The challenge relies on using logic while simultaneously minimizing the risk of guessing. To win, all non-mine squares must be uncovered, leaving only the mines flagged.\n",
    "\n",
    "According to Kaye, “the Minesweeper problem is NP-Complete”, meaning that it is highly unlikely that there is an efficient algorithm that can solve it and that it is just as difficult as any other NP-Complete problem (like the traveling salesman problem)<a name=\"kaye\"></a>[<sup>[1]</sup>](#kayenote). In other words, there is no known algorithm that can solve Minesweeper in polynomial time. Despite that some parts of the board can be determined through logical reasoning, some configurations require probabilistic guessing, making Minesweeper a constraint satisfaction problem<a name=\"studholme\"></a>[<sup>[2]</sup>](#studholmenote).\n",
    "\n",
    "Given these papers, reinforcement learning will be explored in this project. There exists research, where Monte Carlo Simulation was used to solve the Minesweeper problem<a name=\"qing\"></a>[<sup>[3]</sup>](#qingnote). Another study showed that a mix of optimal heuristics proved to solve the problem with more efficiency. Such heuristics included: targeting the corners of the grid based on a previous study<a name=\"studholme\"></a>[<sup>[2]</sup>](#studholmenote) due to the fact that the density of a mine in a corner is lower than any other tiles, maximizing the probability of revealing at least one safe-block in one move, and maximizing the expected number of safe blocks in the next move<a name=\"tu\"></a>[<sup>[4]</sup>](#tunote). This greedy heuristic algorithm was named PSEQ. In a different study, double deep-Q-network was applied to the problem<a name=\"smulders\"></a>[<sup>[5]</sup>](#smuldersnote). For this project, we will focus on implementing the Q-learning algorithm and additional heuristic(s). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Mindsweeper is a puzzle game where it requires players to uncover safe cells while avoiding the mine cells using the adjacent numerical clues. The goal of the game is to uncover the whole entire board without touching a mine. This game requires different strategies and sometimes risk taking when you run out of clues. You have to be able to make the most optimal decision within the stochastic environment where you don’t know where the mine is. The problem we are addressing is developing an AI-based Minesweeper solver that will be the most efficient when in play, using search algorithms and heuristic strategies. This problem is quantifiable since we are able to perform probability calculations and logical inference. It is also measurable since we can calculate the performance based on win rates and average game durations. Lastly, it is replicable since each time you play it is a different game board, allowing us to consistently use our algorithm since the rules do not change. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The data for this project will be generated using a Pygame-based Minesweeper implementation (https://pypi.org/project/pygame-minesweeper/ ). The dataset consists of game states, score ranking, and the final outcome, whether a win or loss. This implementation has various board configurations, such as Basic (10x10 grid with 10 mines), Intermediate (16x16 grid with 40 mines), Expert (6x30 grid with 99 mines), and Custom (users can define the number of rows, columns, and mines). Each board state is represented as a 2D grid where cells can be hidden. They can be revealed with a number indicating the count of adjacent mines, or flagged as a potential mine by the solver. The data collection process involves the solver interacting with the Minesweeper game by tracking wins or loses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "The goal of this project is to develop an agent using Q-learning to solve Minesweeper, a challenging single-player puzzle. The agent will learn to uncover safe tiles while avoiding mines, using exploration and exploitation to optimize its strategy.\n",
    "\n",
    "**Q-learning**\n",
    "\n",
    "The agent’s action space includes selecting tiles to uncover or flag based on the current board state. The terminal test occurs when the agent clicks a mine (ending the game) or successfully uncovers all non-mine tiles. Q-value updates follow the standard Q-learning update rule:\n",
    "\n",
    "$$Q_(t+1)(A_t) = Q_t(A_t) + \\alpha_t (R_t - Q_t(A_t))$$\n",
    "\n",
    "To improve efficiency, heuristics such as corner targeting (prioritizing corners) will be integrated into the learning process.\n",
    "\n",
    "**Benchmark Model**\n",
    "\n",
    "For evaluation, the random agent will serve as a baseline model, selecting actions randomly from the available tiles. The performance will be compared in terms of win rate, time to solve, and number of moves, with the Q-learning agent expected to outperform the random agent in all metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "For the evaluation of the performance of our Minesweeper solver, we plan to utilize the win rate and average game duration as our evaluation metrics. For the win rate, it is calculated as the percentage of games won out of the total games played. Mathematically, this is represented as:\n",
    "\n",
    "Win Rate = (Number of Games Won/ Total Games Played) * 100\n",
    "\n",
    "A higher win rate indicates better performance in solving Minesweeper boards.\n",
    "For the average game duration, we plan to measure how long it takes for the solver to complete a game which is already implemented in the Pygame Minesweeper. Shorter game duration for a successful game indicates better performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minesweeper itself is a pretty ethical game. We will not be using any data that would intrude personal privacy. Our solver will not conflict with any other player’s experience since this is only a single player game. The only concerns that we could possibly have is with our AI methods, where our solution would defeat the purpose of the game and be too overpowered. To prevent any issues, we will make sure to state all the methods that we use and be transparent as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "\n",
    "* *Everyone contributes to the group project and does their share of the work.*\n",
    "* *We will meet bi-weekly to discuss/work on the project.*\n",
    "* *Everyone is communicative about their project work and issues*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/11  |  8 PM |  Brainstorm topics/questions (all)  | Discuss and decide on final project topic; begin background research | \n",
    "| 2/25  |  8 PM |  Complete Project proposal | Discuss ideal dataset(s); find relevant Python packages; discuss heuristics that can optimally solve our problem statement | \n",
    "| 3/11  | 8 PM  | Find relevant Python packages; research more on the topic  | Discuss how to split the components of the algorithm; Work on how to implement the agent   |\n",
    "| 3/14  | 6 PM  | Finalize the coding/algorithms to be implemented | Review results; finalize additional sections such as Discussion and limitations |\n",
    "| 3/15  | 6 PM  | Complete analysis; Draft results/conclusion/discussion| Discuss any last sections if needed for the project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "\n",
    "<a name= \"kayenote\"></a>1.[^](#kaye): Kaye, R. (2000). \"Minesweeper is NP-Complete.\" Retrieved February 13, 2025. From https://academic.timwylie.com/17CSCI4341/minesweeper_kay.pdf <br> \n",
    "<a name= \"studholmenote\"></a>2.[^](#studholme):Studholme, C. (2000). Minesweeper as a Constraint Satisfaction Problem. Unpublished project report. Retrieved February 13, 2025. From https://www.cs.toronto.edu/~cvs/minesweeper/minesweeper.pdf<br> \n",
    "<a name= \"qingnote\"></a>3.[^](#qing):Qing, Y. et al. (2020). Critical exponents and the universality class of a minesweeper percolation model. International Journal of Modern Physics C, Volume 31, Issue 9, id. 2050129. Retrieved February 13, 2025. From https://ui.adsabs.harvard.edu/abs/2020IJMPC..3150129Q/abstract DOI: 10.1142/S0129183120501296 <br> \n",
    "<a name= \"tunote\"></a>4.[^](#tu):Tu, J. (n.d.). Exploring Efficient Strategies for Minesweeper. Retrieved February 13, 2025. From https://cdn.aaai.org/ocs/ws/ws0294/15091-68459-1-PB.pdf .<br> \n",
    "<a name= \"smuldersnote\"></a>5.[^](#smulders): Smulders, B.G.J.P.( 25 Jun 2023) Optimizing minesweeper and its hexagonal variant with deep reinforcement learning. Retrieved February 13, 2025. From https://pure.tue.nl/ws/portalfiles/portal/307404348/Thesis_BDS_Juli_G._Smulders.pdf  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11 (default, Jul 27 2021, 07:03:16) \n[Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
